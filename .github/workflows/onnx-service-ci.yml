name: ONNX Service CI

on:
  push:
    paths:
      - 'onnx_service/**'
      - 'models/**'
      - 'scripts/**'
      - '.github/workflows/onnx-service-ci.yml'
  pull_request:

jobs:
  build-and-smoke:
    permissions:
      contents: read
      packages: write
      id-token: write
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install ML deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-ml.txt
          pip install -r onnx_service/requirements.txt

      - name: Smoke train (produce model checkpoint)
        run: |
          bash scripts/smoke_train.sh

      - name: Convert to ONNX
        run: |
          python scripts/convert_to_onnx.py

      - name: Build Docker image
        run: |
          docker build -t ecg-onnx-service ./onnx_service

      - name: Run container
        run: |
          docker run -d --name ecg-test -p 8000:8000 -v ${{ github.workspace }}/models:/app/models ecg-onnx-service

      - name: Wait for service
        run: |
          for i in {1..20}; do
            if curl -s http://localhost:8000/health | grep -q '"ok": true'; then
              echo "service healthy" && break
            fi
            sleep 3
          done

      - name: Run inference smoke test
        run: |
          python - << 'PY'
import requests, json
sig = [0.1 * __import__('math').sin(2*__import__('math').pi*i/250) for i in range(250*5)]
r = requests.post('http://localhost:8000/infer', json={'signal': sig, 'sampling_rate': 250}, timeout=10)
print('status', r.status_code, r.text[:200])
if r.status_code != 200:
    raise SystemExit('Infer failed')
PY

      - name: Setup Deno
        uses: denoland/setup-deno@v1
        with:
          deno-version: v1.x

      - name: Run analyze-ecg deno tests
        env:
          ONNX_SERVICE_URL: http://localhost:8000
        run: |
          deno test supabase/functions/analyze-ecg --allow-env --allow-net --no-check

      - name: Upload ONNX artifact
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: model.onnx
          path: models/model.onnx

      - name: Login to GHCR
        if: github.ref == 'refs/heads/main'
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Tag and push Docker image
        if: github.ref == 'refs/heads/main'
        run: |
          docker tag ecg-onnx-service ghcr.io/${{ github.repository_owner }}/ecg-onnx-service:${{ github.sha }}
          docker push ghcr.io/${{ github.repository_owner }}/ecg-onnx-service:${{ github.sha }}

      - name: Stop container
        if: always()
        run: |
          docker rm -f ecg-test || true
